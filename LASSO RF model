from collections import Counter

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.preprocessing import StandardScaler
from sklearn.metrics import roc_auc_score, confusion_matrix, roc_curve
from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV
from sklearn.utils import resample
from sklearn.linear_model import LogisticRegressionCV
from sklearn.ensemble import RandomForestClassifier


def get_lasso_min_features_cv(X, y, feature_names, repeats=10, cv=5, save_path=None):

    selected = []

    for seed in range(repeats):
        lasso = LogisticRegressionCV(
            Cs=[0.01, 0.1, 1],
            cv=cv,
            penalty="l1",
            solver="liblinear",
            scoring="roc_auc",
            max_iter=10000,
            random_state=seed,
        )
        lasso.fit(X, y)
        coef = lasso.coef_.flatten()
        selected.extend(list(feature_names[np.where(coef != 0)]))

    counts = Counter(selected)
    min_repeats = repeats
    selected_features = {f for f, c in counts.items() if c >= min_repeats}

    coef = lasso.coef_.flatten()
    nonzero_mask = coef != 0
    selected_names = feature_names[nonzero_mask]
    selected_coefs = coef[nonzero_mask]
    coef_dict = dict(zip(selected_names, selected_coefs))

    if coef_dict:
        sorted_items = sorted(coef_dict.items(), key=lambda x: abs(x[1]))
        sorted_names = [k for k, _ in sorted_items]
        sorted_coefs = [v for _, v in sorted_items]

        plt.figure(figsize=(10, 5))
        plt.barh(range(len(sorted_coefs)), np.abs(sorted_coefs), color="darkblue")
        plt.yticks(range(len(sorted_coefs)), sorted_names)
        plt.xlabel("Absolute LASSO Coefficient", fontsize=14)
        plt.title("LASSO Coefficients of Features", fontsize=16)
        plt.tight_layout()

        if save_path:
            plt.savefig(save_path.replace(".png", "_coef.png"), dpi=300)
        else:
            plt.show()

    return selected_features, coef_dict


def get_rf_top_features_cv(X, y, feature_names, top_n=10, n_splits=10):
    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)
    importances_accum = np.zeros(X.shape[1])

    for train_idx, _ in skf.split(X, y):
        X_train, y_train = X[train_idx], y[train_idx]

        rf = RandomForestClassifier(
            n_estimators=500,
            max_depth=8,
            max_features="sqrt",
            random_state=42,
            n_jobs=-1,
        )
        rf.fit(X_train, y_train)
        importances_accum += rf.feature_importances_

    importances_mean = importances_accum / n_splits
    sorted_idx = np.argsort(importances_mean)[::-1]
    sorted_features = feature_names[sorted_idx]
    sorted_importances = importances_mean[sorted_idx]

    top_features = sorted_features[:top_n]

    plt.figure(figsize=(10, 6))
    plt.scatter(sorted_features, sorted_importances, color="darkblue", s=50, alpha=0.7)
    plt.xlabel("Feature", fontsize=14)
    plt.ylabel("Importance Score", fontsize=14)
    plt.title("Random Forest Feature Importance", fontsize=16)
    plt.xticks(rotation=90, fontsize=10)
    plt.yticks(fontsize=12)
    plt.grid(True, axis="y", linestyle="--", linewidth=0.5, alpha=0.6)

    ax = plt.gca()
    ax.spines["right"].set_visible(False)
    ax.spines["top"].set_visible(False)
    ax.spines["bottom"].set_linewidth(1.2)
    ax.spines["left"].set_linewidth(1.2)

    plt.tight_layout()
    plt.show()

    return set(top_features)


def evaluate_model_lasso(X_train, y_train, X_test, y_test, selected_features, feature_names, pos_label=1):
    indices = [np.where(feature_names == f)[0][0] for f in selected_features]
    X_train_sel = X_train[:, indices]
    X_test_sel = X_test[:, indices]

    clf = LogisticRegressionCV(
        Cs=np.logspace(-3, 2, 20),
        cv=3,
        penalty="l1",
        solver="saga",
        scoring="roc_auc",
        max_iter=10000,
        random_state=0,
    )
    clf.fit(X_train_sel, y_train)
    y_prob = clf.predict_proba(X_test_sel)[:, 1]

    y_true = (y_test == pos_label)
    fpr, tpr, thresholds = roc_curve(y_true, y_prob)
    youden_index = tpr - fpr
    best_threshold = thresholds[np.argmax(youden_index)]

    y_pred = (y_prob >= best_threshold).astype(int)
    cm = confusion_matrix(y_true, y_pred)
    auc = roc_auc_score(y_true, y_prob)
    sens = cm[1, 1] / (cm[1, 1] + cm[1, 0]) if (cm[1, 1] + cm[1, 0]) > 0 else 0
    spec = cm[0, 0] / (cm[0, 0] + cm[0, 1]) if (cm[0, 0] + cm[0, 1]) > 0 else 0

    return auc, sens, spec, best_threshold


def bootstrap_evaluate_model_lasso(
    X_train, y_train, X_test, y_test, selected_features, feature_names,
    pos_label=1, n_bootstrap=5000, plot_roc=True
):
    """
    Bootstrap evaluation of LASSO model; returns mean and 95% CI for AUC, sensitivity, specificity.
    """
    auc_list, sens_list, spec_list = [], [], []

    for i in range(n_bootstrap):
        X_test_boot, y_test_boot = resample(
            X_test, y_test, replace=True, stratify=y_test, random_state=i
        )
        try:
            auc, sens, spec, _ = evaluate_model_lasso(
                X_train, y_train, X_test_boot, y_test_boot,
                selected_features, feature_names, pos_label
            )
            auc_list.append(auc)
            sens_list.append(sens)
            spec_list.append(spec)
        except Exception:
            continue

    def summary_stats(lst):
        return np.mean(lst), np.percentile(lst, 2.5), np.percentile(lst, 97.5)

    auc_mean, auc_ci_low, auc_ci_high = summary_stats(auc_list)
    sens_mean, sens_ci_low, sens_ci_high = summary_stats(sens_list)
    spec_mean, spec_ci_low, spec_ci_high = summary_stats(spec_list)

    print(f"AUC: {auc_mean:.3f} (95% CI: {auc_ci_low:.3f}–{auc_ci_high:.3f})")
    print(f"Sensitivity: {sens_mean:.3f} (95% CI: {sens_ci_low:.3f}–{sens_ci_high:.3f})")
    print(f"Specificity: {spec_mean:.3f} (95% CI: {spec_ci_low:.3f}–{spec_ci_high:.3f})")

    if plot_roc:
        indices = [np.where(feature_names == f)[0][0] for f in selected_features]
        X_train_sel = X_train[:, indices]
        X_test_sel = X_test[:, indices]

        clf = LogisticRegressionCV(
            Cs=np.logspace(-3, 2, 20),
            cv=3,
            penalty="l1",
            solver="saga",
            scoring="roc_auc",
            max_iter=10000,
            random_state=0,
        )
        clf.fit(X_train_sel, y_train)
        y_prob = clf.predict_proba(X_test_sel)[:, 1]

        y_true = (y_test == pos_label)
        fpr, tpr, _ = roc_curve(y_true, y_prob)
        auc_score = roc_auc_score(y_true, y_prob)

        plt.figure(figsize=(6, 5))
        plt.plot(fpr, tpr, color="darkorange", lw=2, label=f"ROC (AUC={auc_score:.3f})")
        plt.plot([0, 1], [0, 1], color="navy", lw=2, linestyle="--")
        plt.xlabel("False Positive Rate")
        plt.ylabel("True Positive Rate")
        plt.legend(loc="lower right")

        textstr = "\n".join(
            (
                f"AUC = {auc_mean:.3f} (95% CI: {auc_ci_low:.3f}–{auc_ci_high:.3f})",
                f"Sensitivity = {sens_mean:.3f} (95% CI: {sens_ci_low:.3f}–{sens_ci_high:.3f})",
                f"Specificity = {spec_mean:.3f} (95% CI: {spec_ci_low:.3f}–{spec_ci_high:.3f})",
            )
        )

        plt.gca().text(
            0.4,
            0.2,
            textstr,
            transform=plt.gca().transAxes,
            fontsize=10,
            verticalalignment="top",
            bbox=dict(
                facecolor="white",
                alpha=0.7,
                edgecolor="none",
                boxstyle="round,pad=0.5",
            ),
        )
        plt.tight_layout()
        plt.show()

    return {
        "auc": (auc_mean, auc_ci_low, auc_ci_high),
        "sensitivity": (sens_mean, sens_ci_low, sens_ci_high),
        "specificity": (spec_mean, spec_ci_low, spec_ci_high),
    }



if __name__ == "__main__":
    df = pd.read_csv("file.csv")
    X = df.iloc[:, 1:].values
    y = df.iloc[:, 0].values
    feature_names = np.array(df.columns[1:])

    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)

    X_train, X_test, y_train, y_test = train_test_split(
        X_scaled, y, test_size=0.3, stratify=y, random_state=100
    )

    def binary_subset(X, y, g1, g2):
        mask = (y == g1) | (y == g2)
        return X[mask], y[mask]

    X_train_ac, y_train_ac = binary_subset(X_train, y_train, 1, 3)
    X_test_ac, y_test_ac = binary_subset(X_test, y_test, 1, 3)
    y_train_ac_bin = (y_train_ac == 3).astype(int)
    y_test_ac_bin = (y_test_ac == 3).astype(int)

    lasso_ac, coef_dict_ac = get_lasso_min_features_cv(
        X=X_train_ac,
        y=y_train_ac_bin,
        feature_names=feature_names,
        repeats=10,
        save_path="lasso_ac.png",
    )
    rf_ac = get_rf_top_features_cv(
        X_train_ac, y_train_ac_bin, feature_names, top_n=10, n_splits=5
    )
    ac_features = lasso_ac.union(rf_ac)

    X_train_bc, y_train_bc = binary_subset(X_train, y_train, 2, 3)
    X_test_bc, y_test_bc = binary_subset(X_test, y_test, 2, 3)
    y_train_bc_bin = (y_train_bc == 3).astype(int)
    y_test_bc_bin = (y_test_bc == 3).astype(int)

    lasso_bc, coef_dict_bc = get_lasso_min_features_cv(
        X=X_train_bc,
        y=y_train_bc_bin,
        feature_names=feature_names,
        repeats=10,
        save_path="lasso_bc.png",
    )
    rf_bc = get_rf_top_features_cv(
        X_train_bc, y_train_bc_bin, feature_names, top_n=10, n_splits=5
    )
    bc_features = lasso_bc.union(rf_bc)

    print("A vs C — LASSO特征：", lasso_ac)
    print("A vs C — RF特征：", rf_ac)
    print("B vs C — LASSO特征：", lasso_bc)
    print("B vs C — RF特征：", rf_bc)

    all_selected = list(lasso_ac) + list(rf_ac) + list(lasso_bc) + list(rf_bc)
    feature_counter = Counter(all_selected)

    common_features = {f for f, count in feature_counter.items() if count >= 3}
    print("出现 ≥3 次的稳定特征集合：", common_features)

    methods = ["LASSO_AC", "RF_AC", "LASSO_BC", "RF_BC"]
    feature_list = sorted(set(all_selected))
    data = []
    for f in feature_list:
        row = [
            int(f in lasso_ac),
            int(f in rf_ac),
            int(f in lasso_bc),
            int(f in rf_bc),
        ]
        data.append(row)

    df_bin = pd.DataFrame(data, index=feature_list, columns=methods)
    print(df_bin)

    sorted_items = sorted(feature_counter.items(), key=lambda x: x[1], reverse=True)
    features_plot, counts = zip(*sorted_items)

    plt.figure(figsize=(10, 6))
    bars = plt.barh(range(len(counts)), counts[::-1])
    plt.yticks(range(len(features_plot)), features_plot[::-1])
    plt.xlabel("Feature Occurrence Count")
    plt.title("Feature Selection Frequency Across Four Models")

    for i, bar in enumerate(bars):
        if counts[::-1][i] >= 3:
            bar.set_color("orange")

    plt.axvline(x=3, color="gray", linestyle="--", label="Threshold: ≥3 times")
    plt.xticks(range(1, max(counts) + 1, 1))
    plt.legend()
    plt.tight_layout()
    plt.show()

    print("\nBootstrap evaluation: A vs C")
    results_ac = bootstrap_evaluate_model_lasso(
        X_train_ac,
        y_train_ac_bin,
        X_test_ac,
        y_test_ac_bin,
        common_features,
        feature_names,
        pos_label=1,
        n_bootstrap=1000,
    )

    print("\nBootstrap evaluation: B vs C")
    results_bc = bootstrap_evaluate_model_lasso(
        X_train_bc,
        y_train_bc_bin,
        X_test_bc,
        y_test_bc_bin,
        common_features,
        feature_names,
        pos_label=1,
        n_bootstrap=1000,
    )
